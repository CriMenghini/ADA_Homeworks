{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 04 - Applied ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Remarks for the easy reading of the work*:\n",
    "The data in use are stored in the folder `Data`, the description is available [here](https://github.com/ADAEPFL/Homework/blob/master/04%20-%20Applied%20ML/DATA.md).\n",
    "All the functions that are mentioned are stored in separate libraries that are specified at each step. For some of them the reading of the documentation is required to understand how certain results are obtained. \n",
    "The *Notebook* organisation is specified in the *Table of contents*.\n",
    "\n",
    "__Important__: due to the precence of interactive plot, we suggest you to visualize the notebook using the following [link](http://nbviewer.jupyter.org/github/CriMenghini/ADA_Homeworks/blob/master/Homework_4/Hw_4.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents\n",
    "1. [Predict the skin color of a soccer player](#task1)\n",
    "    1. [Exploratory Data Analysis, Feature Selection and Feature engineering](#EDA)\n",
    "     1. [Target variable](#target)\n",
    "     2. [Features](#features)\n",
    "    2. [Baseline model](#baseline)\n",
    "     1. [Preprocess variable to be used as input for the classifier](#preproc)\n",
    "     2. [Split train and test](#split)\n",
    "\t3. [Find the model](#tuning)\n",
    "     1. [Cross-validation for tuning parameters](#cvtuning)\n",
    "     2. [Cross-validation to assess the quality of the model](#cvmodel)\n",
    "    4. [Features importance](#impfeat)\n",
    "    5. [Balance the sample, create many regressors and then average the models](#balance)\n",
    "\t6. [*BONUS*](#bonus)\n",
    "2. [Cluster players with dark and light skin colors](#task2)\n",
    "    1. [Sub paragraph](#subparagraph1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Predict the skin color of a soccer player <a name=\"task1\"></a>\n",
    "\n",
    "In this first task we train a *Random forest* classifier to be able to predict the skin color of a soccer player using the player description. In order to do so, we proceed pre-processing the data as first step then moving toward the choice of the model (interpret as the choice of parameters controlling the possible issues i.e. the *overfitting*). As required, we then switch to the inspection of the `feature_importances_` attribute and the discussion of the obtained results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plots import *\n",
    "import plotly.tools as tls\n",
    "from sklearn import metrics\n",
    "from balance_sample import *\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt \n",
    "from data_preprocessing import *\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import *\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "warnings.filterwarnings('ignore')\n",
    "plotly.tools.set_credentials_file(username='crimenghini', api_key='t5q05yuxzu')\n",
    "plotly.tools.set_credentials_file(username='cristina.crocca', api_key='l1up4iv6pj')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerShort</th>\n",
       "      <th>player</th>\n",
       "      <th>club</th>\n",
       "      <th>leagueCountry</th>\n",
       "      <th>birthday</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>position</th>\n",
       "      <th>games</th>\n",
       "      <th>victories</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2</th>\n",
       "      <th>refNum</th>\n",
       "      <th>refCountry</th>\n",
       "      <th>Alpha_3</th>\n",
       "      <th>meanIAT</th>\n",
       "      <th>nIAT</th>\n",
       "      <th>seIAT</th>\n",
       "      <th>meanExp</th>\n",
       "      <th>nExp</th>\n",
       "      <th>seExp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lucas-wilchez</td>\n",
       "      <td>Lucas Wilchez</td>\n",
       "      <td>Real Zaragoza</td>\n",
       "      <td>Spain</td>\n",
       "      <td>31.08.1983</td>\n",
       "      <td>177.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Attacking Midfielder</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>GRC</td>\n",
       "      <td>0.326391</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>750.0</td>\n",
       "      <td>0.002696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>john-utaka</td>\n",
       "      <td>John Utaka</td>\n",
       "      <td>Montpellier HSC</td>\n",
       "      <td>France</td>\n",
       "      <td>08.01.1982</td>\n",
       "      <td>179.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Right Winger</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>0.203375</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.010875</td>\n",
       "      <td>-0.204082</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.061504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abdon-prats</td>\n",
       "      <td>Abdón Prats</td>\n",
       "      <td>RCD Mallorca</td>\n",
       "      <td>Spain</td>\n",
       "      <td>17.12.1992</td>\n",
       "      <td>181.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ESP</td>\n",
       "      <td>0.369894</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.588297</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pablo-mari</td>\n",
       "      <td>Pablo Marí</td>\n",
       "      <td>RCD Mallorca</td>\n",
       "      <td>Spain</td>\n",
       "      <td>31.08.1993</td>\n",
       "      <td>191.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Center Back</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ESP</td>\n",
       "      <td>0.369894</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.588297</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ruben-pena</td>\n",
       "      <td>Rubén Peña</td>\n",
       "      <td>Real Valladolid</td>\n",
       "      <td>Spain</td>\n",
       "      <td>18.07.1991</td>\n",
       "      <td>172.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Right Midfielder</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ESP</td>\n",
       "      <td>0.369894</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.588297</td>\n",
       "      <td>1897.0</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     playerShort         player             club leagueCountry    birthday  \\\n",
       "0  lucas-wilchez  Lucas Wilchez    Real Zaragoza         Spain  31.08.1983   \n",
       "1     john-utaka     John Utaka  Montpellier HSC        France  08.01.1982   \n",
       "2    abdon-prats    Abdón Prats     RCD Mallorca         Spain  17.12.1992   \n",
       "3     pablo-mari     Pablo Marí     RCD Mallorca         Spain  31.08.1993   \n",
       "4     ruben-pena     Rubén Peña  Real Valladolid         Spain  18.07.1991   \n",
       "\n",
       "   height  weight              position  games  victories    ...     rater2  \\\n",
       "0   177.0    72.0  Attacking Midfielder      1          0    ...       0.50   \n",
       "1   179.0    82.0          Right Winger      1          0    ...       0.75   \n",
       "2   181.0    79.0                   NaN      1          0    ...        NaN   \n",
       "3   191.0    87.0           Center Back      1          1    ...        NaN   \n",
       "4   172.0    70.0      Right Midfielder      1          1    ...        NaN   \n",
       "\n",
       "   refNum  refCountry  Alpha_3   meanIAT    nIAT     seIAT   meanExp    nExp  \\\n",
       "0       1           1      GRC  0.326391   712.0  0.000564  0.396000   750.0   \n",
       "1       2           2      ZMB  0.203375    40.0  0.010875 -0.204082    49.0   \n",
       "2       3           3      ESP  0.369894  1785.0  0.000229  0.588297  1897.0   \n",
       "3       3           3      ESP  0.369894  1785.0  0.000229  0.588297  1897.0   \n",
       "4       3           3      ESP  0.369894  1785.0  0.000229  0.588297  1897.0   \n",
       "\n",
       "      seExp  \n",
       "0  0.002696  \n",
       "1  0.061504  \n",
       "2  0.001002  \n",
       "3  0.001002  \n",
       "4  0.001002  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data \n",
    "data = pd.read_csv('Data/CrowdstormingDataJuly1st.csv', sep = ',')\n",
    "# Take a look at the data head\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Exploratory Data Analysis, Feature Selection and Feature engineering <a name=\"EDA\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### a. Target variable <a name=\"target\"></a>\n",
    "\n",
    "Before proceeding with the exploration of the features, we focuse our attention on the target variable (`rater1`, `rater2`). In this case we face the folliwing issues:\n",
    "1. [*Absence of labels*](#absence): Not all the players have an `IDphoto`, thus the *raters* can not label the skin color. It results in a bunch of player not labeled. Since in this first task we work using the *Supervised* learning we drop out all the *dyads* that correspond to players whose picture is not available.\n",
    "\n",
    "2. [*Inconsistency of labels*](#inconsistency): The labels assigned by the two raters for some players disagree. In order to control this inconsistency we think about different approaches. \n",
    "    - Compute the mean of the assigned scores. Whether the classification problem is set up as a *multiclassification* problem (five classes according to the `data description` - 0, 0.25, 0.5, 0.75, 1), if the disagreement of the two classes is greater than 0.25 (absolute value) the computation of the average implies the creation of new classes. Otherwise, whether the classification problem is simplified to the *binary* classification (all those players that have been labeled with $0 < values \\leq 0.5$ belong to class 0, all those whose $0.5 < values \\leq 1$) the values obtained computing the average can be easily assigned to one of the two classes.\n",
    "    - Use the two scores vectors to train the model, defining a *multi target* model whether the problem is set up both as *multiclass* or *binary*.\n",
    "        \n",
    "3. [*Unbalanced sample*](#unbalance): the sample that we analyse turns to be *unbalanced*. It means that there are classes that are more present in the population. This verification leads to the necessity of using different metrics, rather the *simple* accuracy, to evaluate the model, and can be in some way faced using some tecniques to *rebalance* the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Absence of labels  <a name=\"absence\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop out the unlabeled players\n",
    "data_clean = data[(data.photoID.notnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are left with the data for the players that have a picture. We want to check whether given the picture both of the raters assuigned the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Rater 1 does not label', 0, 'players')\n",
      "('Rater 2 does not label', 0, 'players')\n"
     ]
    }
   ],
   "source": [
    "# How many players the rater 1 don't label?\n",
    "miss_rater_1 = sum(data_clean.rater1.isnull())\n",
    "# How many the rater 2?\n",
    "miss_rater_2 = sum(data_clean.rater2.isnull())\n",
    "\n",
    "print ('Rater 1 does not label', miss_rater_1, 'players')\n",
    "print ('Rater 2 does not label', miss_rater_2, 'players')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that both of them label all the players with a picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Inconsistency of labels <a name=\"inconsistency\"></a>\n",
    "\n",
    "##### 2.1. Handle `NaNs`\n",
    "Before analysing the *target* we should control whether there is the precence of `NaN` values, that can eventually lead to the elimitation of players, in the dataset, then we *aggregate* by the player. It is important to check the precence of null values before the aggregation for two reasons:\n",
    "* It is possible that some dyads do not contain certain values, it does not imply that in the dataset we can not find other dyads that contain the information. Hence, we remove the dyads or, if possible, assign the value (according to the kind of attribute) so that we don't loose the player.\n",
    "* The precence of `NaN` can cause problems whether an aggregation function is applied. That's because they may propagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the dictionary {key:value} whose key is the attributed with NaNs and value are the indices\n",
    "variables_with_nan = {}\n",
    "\n",
    "# For each attribute\n",
    "for attribute in data_clean.columns:\n",
    "    # Check if there are nans\n",
    "    index_nan = data_clean[attribute].isnull()\n",
    "    presence_nan = sum(index_nan)\n",
    "    \n",
    "    if presence_nan != 0:\n",
    "        variables_with_nan[attribute] = index_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the variables with `NaNs` is listed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weight', 'meanIAT', 'nExp', 'height', 'nIAT', 'seIAT', 'seExp', 'Alpha_3', 'position', 'meanExp']\n"
     ]
    }
   ],
   "source": [
    "print(variables_with_nan.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed considering the attributes related to the players: `weight`, `height`, `position`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "players_attributes = ['weight', 'height', 'position']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we clean the dataframe, the documentation related to the function [`remove_nans`](data_preprocessing.py) provides the explanation related to the procedure used to remove `NaNs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_clean = remove_nans(data_clean, variables_with_nan, players_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove ~21% of the dyads, but the number of drop player is controlled by the approach used to remove the `NaNs`. In fact we remove just those player whose important description feature are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of removed dyads: ', 30425)\n",
      "('Percentage of the removed dyads: ', 0.0, '%')\n"
     ]
    }
   ],
   "source": [
    "print ('Number of removed dyads: ', data.shape[0] - data_clean.shape[0])\n",
    "print ('Percentage of the removed dyads: ', round((data.shape[0] - data_clean.shape[0])/len(data)*100,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we aggregate by player and we observe that we proceed the analysis taking into account ~90% of the players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Group by the player\n",
    "player_data = data_clean.groupby('playerShort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of players: ', 1419)\n",
      "('Percentage of analysed players: ', 0.0, '%')\n"
     ]
    }
   ],
   "source": [
    "print ('Number of players: ', len(player_data))\n",
    "print ('Percentage of analysed players: ', round(len(player_data)/1586*100, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using the aggregation functions for some attributes we check whether aggregating we risk to loose some information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Each player belongs to: ', 1, 'club.')\n",
      "('Each player registers:', 1, 'position.')\n",
      "('Each player registers: ', 1.0, 'weight.')\n",
      "('Each player registers: ', 1.0, 'height.')\n"
     ]
    }
   ],
   "source": [
    "# Check that each player belongs to one club\n",
    "print ('Each player belongs to: ', player_data.agg({'club' : lambda x: len(set(x))})['club'].unique()[0], 'club.')\n",
    "# Check that each player registers one position\n",
    "print ('Each player registers:', player_data.agg({'position' : lambda x: len(set(x))})['position'].unique()[0], 'position.')\n",
    "# Check that each player registers one weight\n",
    "print ('Each player registers: ', player_data.agg({'weight' : lambda x: len(set(x))})['weight'].unique()[0], 'weight.')\n",
    "# Check that each player registers one height\n",
    "print ('Each player registers: ', player_data.agg({'height' : lambda x: len(set(x))})['height'].unique()[0], 'height.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the aggregation function\n",
    "players = player_data.agg({'club' : 'first',\n",
    "                           'leagueCountry' : 'first',\n",
    "                           'birthday' : 'first',\n",
    "                           'height' : 'first',\n",
    "                           'weight' : 'first',\n",
    "                           'position' : 'first',\n",
    "                           'games' : 'sum',\n",
    "                           'victories' : 'sum',\n",
    "                           'ties' : 'sum',\n",
    "                           'defeats' : 'sum',\n",
    "                           'goals' : 'sum',\n",
    "                           'yellowCards': 'sum',\n",
    "                           'yellowReds': 'sum',\n",
    "                           'redCards' : 'sum',\n",
    "                           'rater1' : 'mean',\n",
    "                           'rater2' : 'mean',\n",
    "                           #'refNum' : 'count',\n",
    "                           #'refCountry' : 'count',\n",
    "                           #'meanIAT' : 'mean',\n",
    "                           #'meanExp' : 'mean'\n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>club</th>\n",
       "      <th>leagueCountry</th>\n",
       "      <th>birthday</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>position</th>\n",
       "      <th>games</th>\n",
       "      <th>victories</th>\n",
       "      <th>ties</th>\n",
       "      <th>defeats</th>\n",
       "      <th>goals</th>\n",
       "      <th>yellowCards</th>\n",
       "      <th>yellowReds</th>\n",
       "      <th>redCards</th>\n",
       "      <th>rater1</th>\n",
       "      <th>rater2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playerShort</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaron-hughes</th>\n",
       "      <td>Fulham FC</td>\n",
       "      <td>England</td>\n",
       "      <td>08.11.1979</td>\n",
       "      <td>182.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Center Back</td>\n",
       "      <td>654</td>\n",
       "      <td>247</td>\n",
       "      <td>179</td>\n",
       "      <td>228</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron-hunt</th>\n",
       "      <td>Werder Bremen</td>\n",
       "      <td>Germany</td>\n",
       "      <td>04.09.1986</td>\n",
       "      <td>183.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Attacking Midfielder</td>\n",
       "      <td>336</td>\n",
       "      <td>141</td>\n",
       "      <td>73</td>\n",
       "      <td>122</td>\n",
       "      <td>62</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron-lennon</th>\n",
       "      <td>Tottenham Hotspur</td>\n",
       "      <td>England</td>\n",
       "      <td>16.04.1987</td>\n",
       "      <td>165.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Right Midfielder</td>\n",
       "      <td>412</td>\n",
       "      <td>200</td>\n",
       "      <td>97</td>\n",
       "      <td>115</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaron-ramsey</th>\n",
       "      <td>Arsenal FC</td>\n",
       "      <td>England</td>\n",
       "      <td>26.12.1990</td>\n",
       "      <td>178.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Center Midfielder</td>\n",
       "      <td>260</td>\n",
       "      <td>150</td>\n",
       "      <td>42</td>\n",
       "      <td>68</td>\n",
       "      <td>39</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abdelhamid-el-kaoutari</th>\n",
       "      <td>Montpellier HSC</td>\n",
       "      <td>France</td>\n",
       "      <td>17.03.1990</td>\n",
       "      <td>180.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Center Back</td>\n",
       "      <td>124</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     club leagueCountry    birthday  height  \\\n",
       "playerShort                                                                   \n",
       "aaron-hughes                    Fulham FC       England  08.11.1979   182.0   \n",
       "aaron-hunt                  Werder Bremen       Germany  04.09.1986   183.0   \n",
       "aaron-lennon            Tottenham Hotspur       England  16.04.1987   165.0   \n",
       "aaron-ramsey                   Arsenal FC       England  26.12.1990   178.0   \n",
       "abdelhamid-el-kaoutari    Montpellier HSC        France  17.03.1990   180.0   \n",
       "\n",
       "                        weight              position  games  victories  ties  \\\n",
       "playerShort                                                                    \n",
       "aaron-hughes              71.0           Center Back    654        247   179   \n",
       "aaron-hunt                73.0  Attacking Midfielder    336        141    73   \n",
       "aaron-lennon              63.0      Right Midfielder    412        200    97   \n",
       "aaron-ramsey              76.0     Center Midfielder    260        150    42   \n",
       "abdelhamid-el-kaoutari    73.0           Center Back    124         41    40   \n",
       "\n",
       "                        defeats  goals  yellowCards  yellowReds  redCards  \\\n",
       "playerShort                                                                 \n",
       "aaron-hughes                228      9           19           0         0   \n",
       "aaron-hunt                  122     62           42           0         1   \n",
       "aaron-lennon                115     31           11           0         0   \n",
       "aaron-ramsey                 68     39           31           0         1   \n",
       "abdelhamid-el-kaoutari       43      1            8           4         2   \n",
       "\n",
       "                        rater1  rater2  \n",
       "playerShort                             \n",
       "aaron-hughes              0.25    0.00  \n",
       "aaron-hunt                0.00    0.25  \n",
       "aaron-lennon              0.25    0.25  \n",
       "aaron-ramsey              0.00    0.00  \n",
       "abdelhamid-el-kaoutari    0.25    0.25  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['club', 'leagueCountry', 'birthday', 'height', 'weight', 'position', 'games', 'victories', 'ties', 'defeats', 'goals', 'yellowCards', 'yellowReds', 'redCards', 'rater1', 'rater2']\n",
    "players = players[columns]\n",
    "players.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2. Analyse the target  <a name=\"rater12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the new dataframe we extract the two variables that correspond to the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract labels\n",
    "label_1 = players['rater1']\n",
    "label_2 = players['rater2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the distribution of the labels related to the two raters are different. It shows the disagreement aforementioned. In particular, the first classifies the 75% of the players as *very light skin*, *light skin*, the number of players classified as *dark skin* or *very dark skin* is so low that the are outside the *Inter-Quartile Range*. The second rated evidence the tendency of giving higher scores. Since we do not have another rater to compare, we can't make an assumption on the reliability of the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cristina.crocca/27.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#boxplot_raters(label_1, label_2)\n",
    "tls.embed('https://plot.ly/~cristina.crocca/27')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Unbalanced sample <a name=\"unbalance\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the view of what we observed in the [previous](#rater12) section, we see that our sample suffers of the lack of samples that are recognized as *dark skin* or *very dark skin*. We show more clearly with the following plot the unbalancement. In particular we see that both the *Rater 1* and *Rater 2* classify in the first three classes more than the 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cristina.crocca/29.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stacked_plot(label_1,label_2)\n",
    "tls.embed(\"https://plot.ly/~cristina.crocca/29\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This verification implies important consideration for the further analysis. \n",
    "1. We redifine the goal of our analysis as a *Binary Classification* problem. We consider it enough to distinguish a \"light skin\" player from a \"dark skin\". In particular the Labels are encoded according to the intervals defined [above](#target). This choice can help us in facing the *unbalancement* of our sample and reduce the complexity of our classification problem. \n",
    "2. So far we used the *Accuracy* metric in order to evaluate the accuracy of the model. We will replace it with some other metric. The reason behind it comes from the definition of the accuracy. It is a ratio of the correct prediction over the total sample to predict. Due to the presence of a class (*light skin*) that represents the majority in the sample, the classifier is able to classify this class well. In particular it tends to classify all the observation as that class (we will look at the confusion matrices later). Thus, the accuracy results to be very good just because of the high precence of the class in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we encode the labels according to the binary classification problem. Before encoding the labels we merge the rates given by the two raters by averaging the scores. The function is stored in [`data_preprocessing`](data_preprocessing.py) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_merged = (label_1 + label_2)/2\n",
    "labels = label_merged.apply(binary_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "players.drop('rater1', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "players.drop('rater2', axis= 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Features <a name=\"features\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we focuse on the study of the other features in our dataset. In particular, for the moment we avoid to take into account the information related to the [referee](#referee) (features realated to the `IAT` and `Exp`, `refCountry`).\n",
    "In an ideal world, where the racism is not present on a soccer's field, the [phisical characteristics](#physical) of a player (and the features that derives from them) should be the only really useful to classify a player as black or white. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Physical features <a name=\"physical\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, the following plot tries to visualize how some features vary according to the the skin color of a player. We choose as features to plot:\n",
    "- `leagueCountry`: It may be possible that in some leagues there is an higher presece of players with different skin colors.\n",
    "- `club`: Some clubs may decide to buy players according to the physical characteristics of players with *light* or *dark* skin color.\n",
    "- `yellowCards`: We focuse on the average number of yellow cards registered in each team. \n",
    "- `weight`, `height`: Physical characteristics. It may be plausible that *light* skin soccer players have different pysical characteristics respect the *dark* skin ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each bubble represents a `club`. The diameter of the bubbles shows the proportion of *dark* skin players in the club. The colour of the bubbles corresponds to the `League` the club is part of. The legend shows different sizes, bigger is the point greater is the average percentage of *dark* players in the `League`. The pop-up of each bubbles describe the characteristics of the `club`. It is important to notice that there are few bubbles that result to be extramly big and that register the 100% presence of *dark* skin players, just because he is the only player in the team!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cristina.crocca/0.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bubble_plot(labels, players, 'yellowCards', 'mean', 'weight', 'mean', 'height', 'mean')\n",
    "tls.embed(\"https://plot.ly/~cristina.crocca/0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot is interesting. We can infer that knowing the League which the player belongs may be a good variable for our model. Taking a look at the bubbles of the same color, we see that the clubs whose proportion of *dark* skin players is similar tend to have similar values related to the average height and weight. Respect the number of `Yellow cards`, using the pop-ups, we are not able to find a kind of *path* toward the skin color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Referee features <a name=\"referee\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing that we inspect is the distribution of the average `meanIAT` and `meanExp`. We infer that the average `meanIAT` and `meanExp` of the referees who umpire the games of *light* skin players tend to have higher values. We do not think that the features related to this scores should be part of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cristina.crocca/6.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#boxplot_plotly(players, labels, 'meanIAT')\n",
    "tls.embed('https://plot.ly/~cristina.crocca/6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cristina.crocca/9.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#boxplot_plotly(players, labels, 'meanExp')\n",
    "tls.embed('https://plot.ly/~cristina.crocca/9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check whether a relationship between the number of yellow cards obtained by a player (by making the distrinction between *light* and *dark* skin) appears to be, in some sense, dependent on the average of the `meanIAT` values of all the referee a player play with. As shown in the plot below, it is not possible to identify a real path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cristina.crocca/13.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scatter_plot(players, labels)\n",
    "tls.embed('https://plot.ly/~cristina.crocca/13')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Baseline model  <a name=\"baseline\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model than we consider takes as inputs all the variables except the `refNum`, `refCountry`, the standard deviation of `meanIAT` and `meanExp` and the cardinality of the population the information (related to the latter features) have been inferred.\n",
    "\n",
    "Before feeding the model with the features, we proceed as follows:\n",
    "\n",
    "1. We [preprocess](#preproc) the different features:\n",
    " 1. Birthday: just keep the year\n",
    " 2. Categorization of numerical features when they present more than 12 different values\n",
    " 3. Encoding of the 'object' attributes according to what is required by the `sklearn`'s `RandomForest` classifier.\n",
    "\n",
    "2. We [split](#split) the entire data into train and test set (respectively 80% and 20%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess variable to be used as input for the classifier  <a name=\"preproc\"></a>\n",
    "\n",
    "The procedures used to preprocess the data are wrapped in functions sored in the [`data_preprocessing`](data_preprocessing.py) library. Inside the function is provided the documentation to understand what we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keep only the year of the birthday\n",
    "players['birthday'] = players['birthday'].apply(lambda x: float(x.split('.')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Object features: ', ['club', 'leagueCountry', 'position'])\n",
      "('Numerical features: ', ['birthday', 'height', 'weight', 'games', 'victories', 'ties', 'defeats', 'goals', 'yellowCards'])\n"
     ]
    }
   ],
   "source": [
    "# Get the string variables\n",
    "object_features = [i for i in players.columns if players[i].dtypes == 'object']\n",
    "print ('Object features: ', object_features)\n",
    "\n",
    "\n",
    "# Get the list of the numerica variables\n",
    "numerical_features = [i for i in players.columns if (players[i].dtypes == 'int64' or players[i].dtypes == 'float64') and len(players[i].unique()) > 12]\n",
    "print ('Numerical features: ',numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode string variables\n",
    "for feature in object_features:\n",
    "    encode_string_variable(players, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Categorise the numerical features\n",
    "for i in range(len(numerical_features)):\n",
    "    players[numerical_features[i]] = players[numerical_features[i]].apply(partial(categorisation, create_bins(players, numerical_features[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the pre-processed dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>club</th>\n",
       "      <th>leagueCountry</th>\n",
       "      <th>birthday</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>position</th>\n",
       "      <th>games</th>\n",
       "      <th>victories</th>\n",
       "      <th>ties</th>\n",
       "      <th>defeats</th>\n",
       "      <th>goals</th>\n",
       "      <th>yellowCards</th>\n",
       "      <th>yellowReds</th>\n",
       "      <th>redCards</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playerShort</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>steven-reid</th>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moussa-sissoko</th>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guillaume-hoarau</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marc-hornschuh</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mata</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  club  leagueCountry  birthday  height  weight  position  \\\n",
       "playerShort                                                                 \n",
       "steven-reid         87              0         5      12       6         9   \n",
       "moussa-sissoko      81              1        10      16       8         0   \n",
       "guillaume-hoarau    56              1         7      19       7         2   \n",
       "marc-hornschuh      16              2        11      17       6         1   \n",
       "mata                20              0         9       5       1         0   \n",
       "\n",
       "                  games  victories  ties  defeats  goals  yellowCards  \\\n",
       "playerShort                                                             \n",
       "steven-reid           4          3     5        5      0            4   \n",
       "moussa-sissoko        4          3     5        5      1            3   \n",
       "guillaume-hoarau      3          2     4        2      2            1   \n",
       "marc-hornschuh        2          2     3        3      0            1   \n",
       "mata                  6          6     6        5      4            2   \n",
       "\n",
       "                  yellowReds  redCards  \n",
       "playerShort                             \n",
       "steven-reid                0         1  \n",
       "moussa-sissoko             1         0  \n",
       "guillaume-hoarau           1         0  \n",
       "marc-hornschuh             0         1  \n",
       "mata                       0         0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Split train and test  <a name=\"split\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(players, labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fact that our sample is [unbalanced](#unbalance), we try to mitigate its effect exploiting some `sklearn` [spells](http://gph.is/1sGDBKR). In particular, we provide to the model the weigths of the two classes inside the train population, in such a way that it uses it during the training. The code is provided in the [`balance_sample`](balance_sample.py) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the sample weights of the train\n",
    "sample_weights = weight_sample(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we setu up our classifier. For the *baseline* model we do not care about the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, random_state=1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we train the classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_forest = forest.fit(X_train, y_train, sample_weight= sample_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And get the predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict = train_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we get the *accuracy* of the model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy of the model: ', 0.84154929577464788)\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy of the model: ', metrics.accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting no efforts the classifere already returns a good level of accuracy, that is the proportion of *True positive* and *True false* over the all population to predict. To be sure that the accuracy is a good metric to consider we take a look at the confusion matrix <a name=\"confmatr\"></a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Confusion matrix: \\n', array([[236,   3],\n",
      "       [ 42,   3]]))\n"
     ]
    }
   ],
   "source": [
    "print ('Confusion matrix: \\n',\n",
    "       metrics.confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see the classifier is able to classify correctly almost all the players with *Light* skin, but it commits a lot of mistakes in the classification of the *Dark* skin players. Infact only a little portion is correctly classified  (recall score considering the *Dark skin* as the positive value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Recall for the Dark skin class: ', 0.066666666666666666)\n"
     ]
    }
   ],
   "source": [
    "print ('Recall for the Dark skin class: ', metrics.recall_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This verification suggests us that, due to the unbalance of the sample, the accuracy is not the most appripriate way to measure the quality of our model. So we use as metrics the ROC-AUC <a name=\"roc_auc\"></a> score and the [F_BETA](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html) that is the weighted harmonic mean of precision and recall. In particular we assign to *beta* a value greater than 1 to give more relevance to the *recall*, in order to check whether our classifier is aslso able to recognize the *dark* skin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AUC : ', 0.52705718270571822)\n"
     ]
    }
   ],
   "source": [
    "print ('AUC : ',metrics.roc_auc_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the AUC shows that our classifier is not so far from a random classifier!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('F beta : ', 0.082101513802315215)\n"
     ]
    }
   ],
   "source": [
    "print ('F beta : ', metrics.fbeta_score(y_test, predict, beta=1.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metric above gets value between 0 and 1. Its optimal value is 1 and its worst value is 0. We can't definitely say the our estimator is good enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### C. Find the model <a name=\"tuning\"></a>\n",
    "\n",
    "Now we proceed with the cross-validation to do two things:\n",
    "1. Tuning the parameters *max_depth* and *n_estimators*, namely we want to control how the model behaves when we reduce or increase its complexity.\n",
    "2. We run a simple cross-validation to check the quality of the classifier with different data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Cross-validation for tuning parameters <a name=\"cvtuning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The run CV is a *K-folders* where K=10. The function used is the [`tuning_cv`](balance_sample.py), the documentation inside the library provides all the information about the implemented procedure. It recalls the [`cross_validation`](balance_sample.py) that we implemented from scratch in order to get additional information like the train \"accuracy\" and the standard deviation of both the *train* and *test* \"accuracy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "average_roc_train, std_roc_train, average_fbeta_train, std_fbeta_train, average_roc_test, std_roc_test, average_fbeta_test, std_fbeta_test, couples_estimators = tuning_cv(players, labels, list_depths = range(4,50, 5), list_numbers_estimators = range(4,100, 5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, for each combination of `depth` and `number of estimators` we plot the average AUC and Fbeta obtained during the *CV*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cristina.crocca/19.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_test_plot(couples_estimators, average_roc_train, average_roc_test, average_fbeta_train, average_fbeta_test, plot_name='train_test')\n",
    "tls.embed('https://plot.ly/~cristina.crocca/19')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the graph we clearly see that our classifier overfits. The train error is always a way higher than the test error. Our model is too complex. We can notice a decreasing trend for the test *AUC* and *Fbeta* that shows that increasing the depth and the number of estimators of the classifiers (increasing the complexity of the model) we continue to reduce the bias in the model making it too sticky to the train data points and inducing a lack of generality. Moreovere, looking at the AUC scores, again, our model doesn't seem to be way better than a random classifier!!!\n",
    "\n",
    "Anyway, we have to choose the parameters that we want to use for our output model. We prefer those whose FBeta is higher. But before making the final choice we also take a look at the standard deviations of test FBeta. In particular, for the sake of the graph interpretation, we get focused on the first 30 combinations of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cristina.crocca/23.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#error_bars(couples_estimators[:30], average_fbeta_test[:30], std_fbeta_test[:30])\n",
    "tls.embed('https://plot.ly/~cristina.crocca/23')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the parameters that we choose are `n_estimators`=9 and `max_depth`=24 (corresponding to the 14th combination). From the plot above we can see that, even if the variance of the *Fbeta* obtained during the *CV* is higher than the other group of *parameters couple* (from 4 to 9), the possible values of the *FBeta* are still better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation to assess the quality of the model <a name=\"cvmodel\"></a>\n",
    "\n",
    "Then, we run the *CV* to see the scores obtained by our model. In particular, we fit the classifier on the train and test sets used [above](#split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fefine the classifier\n",
    "forest = RandomForestClassifier(n_estimators=9, max_depth=24, random_state=1, class_weight='balanced')\n",
    "\n",
    "# Cross validation\n",
    "n_fold = 10\n",
    "cv_scores = cross_val_score(forest, X_train, y_train, cv=n_fold, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cristina.crocca/31.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot_cv_scores(n_fold, cv_scores)\n",
    "tls.embed('https://plot.ly/~cristina.crocca/31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('On average, the F score in the 10-folds is :', 0.18551828847481025, '. The model has still too low bias.')\n"
     ]
    }
   ],
   "source": [
    "print ('On average, the F score in the 10-folds is :', np.mean(cv_scores), '. The model has still too low bias.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features importance <a name=\"impfeat\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now move to the evaluation of the features in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "forest.fit(X_train, y_train)\n",
    "# Compute the features importance\n",
    "importances = forest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~crimenghini/4.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot_features_importance(players, importances)\n",
    "tls.embed('https://plot.ly/~crimenghini/4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can happily announce that our beloved [`pandas`](http://gph.is/1LLTeqz) wins its battle against racism! In fact, in our model, the features related to the behaviour of the referees are not as important as the ones that refer to the *\"description\"* of a player. So, whether we would be interested in performing the model with few input features, we could do it using those related only to the players."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Balance the sample, create many regressors and then average the models  <a name=\"balance\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the high effects that the composition of the sample has on the performances of our model, we decide to proceed as follow (the procedure is applied on the train, the test will be used later to perform the model).\n",
    "\n",
    "1. [Classes presence in the train data set](#class) We observe that the weights of the train set are ~84% for the *light skin* and ~16% for the *dark skin*\n",
    "2. [Create the  data sets which the model will be run on](#create) We create M new dataframe that will have the two classes in an equal proportion. \n",
    "3. [Train each classifier and make prediction](#train) We run a Random Forest to each dataset, then we compute the prediction.\n",
    "4. [Average the models](#average): voting procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Classes presence in the train data set <a name=\"class\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    953\n",
      "1    182\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Compute the number of players present in the two classes\n",
    "weight_class = y_train.value_counts()\n",
    "print (weight_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Create the  data sets which the model will be run on <a name=\"create\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create the data sets we proceed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Distinguish between the dataframe that corresponds to the \"light\" skin and the \"dark\" skin classes\n",
    "X_class_0 = X_train[y_train == 0]\n",
    "X_class_1 = X_train[y_train == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the `X_class_0` we extract a 5 (proportion of *light* on *dark*) random samples. Each of this sample is concatenated to the `X_class_1`. Thus, we have 5 *\"homogeneous\"* (balanced) datasets which our model will be fit on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Randomly draw the indexes of the X_class_0 samples which will compose the new dfs\n",
    "indexes = players_chunks(int(weight_class[0]/weight_class[1]), np.random.permutation(X_class_0.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we proceed creating the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_1, y_1_train, X_2, y_2_train, X_3, y_3_train, X_4, y_4_train, X_5, y_5_train =  create_df(X_class_0, X_class_1, y_train, indexes, n_df=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Train each classifier and make prediction  <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of our readers, we are not going to optimize the predictions of our model. In fact, our purpose is just to show that this kind of approach can control better the unbalancement present in our data. Hence, we are going to set the same parameters for each forest. We try to avoid to create models that are to complex, in order to avoid the overfitting. Moreover, we run a 10-fold cross validation to see how the classifier behaves with different points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the forest\n",
    "forest = RandomForestClassifier(n_estimators=40, max_depth=10 ,random_state=1)\n",
    "\n",
    "# Compute the CV on X1\n",
    "f1_score_X1 = cross_val_score(forest, X_1, y_1_train, cv=10, scoring='f1')\n",
    "\n",
    "# Compute the CV on X2\n",
    "f1_score_X2 = cross_val_score(forest, X_2, y_2_train, cv=10, scoring='f1')\n",
    "\n",
    "# Compute the CV on X3\n",
    "f1_score_X3 = cross_val_score(forest, X_3, y_3_train, cv=10, scoring='f1')\n",
    "\n",
    "# Compute the CV on X4\n",
    "f1_score_X4 = cross_val_score(forest, X_4, y_4_train, cv=10, scoring='f1')\n",
    "\n",
    "# Compute the CV on X5\n",
    "f1_score_X5 = cross_val_score(forest, X_5, y_5_train, cv=10, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~crimenghini/16.embed\" height=\"525\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the results\n",
    "#balance_cv_plot(f1_score_X1, f1_score_X2, f1_score_X3, f1_score_X4, f1_score_X5, n_fold = 10)\n",
    "tls.embed('https://plot.ly/~crimenghini/16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing these results with the once obtained before we see that each classifier results to be much metter than the one computed [before](#cvmodel).\n",
    "\n",
    "Then, we obtain the predictions for each classifier for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train classifier 1\n",
    "train_forest = forest.fit(X_1, y_1_train)\n",
    "# Obtain predictions\n",
    "predict_1 = train_forest.predict(X_test)\n",
    "\n",
    "# Train classifier 2\n",
    "train_forest = forest.fit(X_2, y_2_train)\n",
    "# Obtain predictions\n",
    "predict_2 = train_forest.predict(X_test)\n",
    "\n",
    "# Train classifier 3\n",
    "train_forest = forest.fit(X_3, y_3_train)\n",
    "# Obtain predictions\n",
    "predict_3 = train_forest.predict(X_test)\n",
    "\n",
    "# Train classifier 4\n",
    "train_forest = forest.fit(X_4, y_4_train)\n",
    "# Obtain predictions\n",
    "predict_4 = train_forest.predict(X_test)\n",
    "\n",
    "# Train classifier 5\n",
    "train_forest = forest.fit(X_5, y_5_train)\n",
    "# Obtain predictions\n",
    "predict_5 = train_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Average the models <a name=\"average\"></a>\n",
    "\n",
    "We average the outputs of the three classifiers using the voting procedure. Namely, we look at the predictions of all the estimator for each player and then we classify him with the lables with the highest occurrences. The functions are provided in [the library](balance_sample.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   274  275  276  277  \\\n",
       "0    0    1    0    0    0    1    1    1    0    1 ...     0    0    0    0   \n",
       "1    0    1    0    0    1    1    1    0    0    1 ...     0    1    0    0   \n",
       "2    0    1    1    0    0    1    0    1    0    1 ...     1    0    0    1   \n",
       "3    0    1    1    0    0    0    1    1    1    1 ...     0    0    0    0   \n",
       "4    0    1    1    0    0    1    1    1    0    1 ...     1    0    0    0   \n",
       "\n",
       "   278  279  280  281  282  283  \n",
       "0    0    1    1    0    0    0  \n",
       "1    0    0    1    0    0    0  \n",
       "2    0    0    1    0    0    0  \n",
       "3    0    0    1    0    0    0  \n",
       "4    0    1    1    0    0    0  \n",
       "\n",
       "[5 rows x 284 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe of prediction (rows: classifiers, columns: players)\n",
    "prediction_df = pd.DataFrame([predict_1.T, predict_2.T, predict_3.T, predict_4.T, predict_5.T])\n",
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply the voting procedure\n",
    "average_model_predictions = voting_procedure(prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the just obtained results to those obtaines before we see that we obtain considerable improvments if we take a look at the [confusion matrix](#confmatr). In fact we see that now the classifier is better in recognizing the *Dark* skin players, and it does not just point to the class of *light* skin color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Confusion matrix: \\n', array([[168,  71],\n",
      "       [ 25,  20]]))\n"
     ]
    }
   ],
   "source": [
    "print ('Confusion matrix: \\n',\n",
    "       metrics.confusion_matrix(y_test, average_model_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compare also the AUC and the Fbeta with the ones obtained [above](#roc_auc). We observe a quite satisfing improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AUC : ', 0.57368665736866575)\n"
     ]
    }
   ],
   "source": [
    "print ('AUC : ', metrics.roc_auc_score(y_test, average_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('F beta : ', 0.3637798382323929)\n"
     ]
    }
   ],
   "source": [
    "print ('F beta : ', metrics.fbeta_score(y_test, average_model_predictions, beta=1.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### *BONUS* <a name=\"bonus\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to test the parameters for the *RandomForestClassifier* in order to obtain the view of the bias and variance in the train and test data. We are going to draw the learning curves. We will use cross-validation with 20 folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first see the curve that shows the parameters for the RandomForest (values for n_estimators and max_depth) that leads it to overfit the training set. We can see that the curves are far away from each other. The model is so complex that even increasing the set of samples doesn't change its performance. Especially for the test dataset it doesn't improve the prediciton. We used [this]( http://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html) implementation for learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'learning_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-59f943315cac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_learning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Learning curves (overfit)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/josselin/ADA/ADA_Homeworks/Homework_4/plots.pyc\u001b[0m in \u001b[0;36mplot_learning_curve\u001b[0;34m(estimator, title, X, y, ylim, cv, n_jobs, train_sizes)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m     \u001b[0;31m# Compute the learning curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     train_sizes, train_scores, test_scores = learning_curve(\n\u001b[1;32m    524\u001b[0m         estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'learning_curve' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAGHCAYAAACJeOnXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEmS1DkDiCRJ6pwBRJIkde7/A/oD+IhtJN9RAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efee5ff5e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learning_curve(RandomForestClassifier(n_estimators=75, max_depth=75), 'Learning curves (overfit)', X_train, y_train, cv = ShuffleSplit(n_splits=20, test_size=0.2, random_state=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to contrary we will show the set of parameters that decreases the performance of the classifier and leads to high bias. On the other hand such model is more general. We can observe loss of accuracy for the training set the more samples we take the worst performance we have. But in parallel we get the stable prediction for the test dataset. We see that having large sample accuracy curves of train and test sets get closer. It means that our model tends to be more reusable. Having such general model prevents us from overfitting and leads to better practical applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_learning_curve(RandomForestClassifier(n_estimators=15, max_depth=5), 'Learning curves (high bias)', X_train, y_train, cv = ShuffleSplit(n_splits=20, test_size=0.2, random_state=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cluster players with dark and light skin colors <a name=\"task2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this part, we start with the cleaned and grouped player_data used in the previous part, we define the following aggregation function for the features that we categorise as referee information, namely :\n",
    "\n",
    "* leagueCountry : Where the matche(s) have been refered.\n",
    "* games : The number of games is close from the number of referees a player has been in contact with.\n",
    "* victories : Can be highly correlated with a favourable referee.\n",
    "* defeats : Can be highly correlated with an unfavourable referee.\n",
    "* goals : An unfavourable referee can result in a lower goal output.\n",
    "* yellowCards, yellowReds, redCards : Can be highly correlated to an unfavorable referee.\n",
    "* meanIAT, meanExp: The aggregated data can potientially show how \"racist\" the referees may have been according to where they come from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the aggregation function on the grouped data\n",
    "ref_agg = player_data.agg({\n",
    "                           'leagueCountry' : 'first',\n",
    "                           'games' : 'sum',\n",
    "                           'victories' : 'sum',\n",
    "                           'defeats' : 'sum',\n",
    "                           'goals' : 'sum',\n",
    "                           'yellowCards': 'sum',\n",
    "                           'yellowReds': 'sum',\n",
    "                           'redCards' : 'sum',\n",
    "                           'rater1' : 'mean',\n",
    "                           'rater2' : 'mean',\n",
    "                           'meanIAT' : 'mean',\n",
    "                           'meanExp' : 'mean',\n",
    "                          })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the aggregated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ref_agg.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorder the columns for preprocessing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['rater1', 'rater2','leagueCountry', 'games', 'victories', 'defeats','goals', 'yellowCards', 'yellowReds', 'redCards', 'meanIAT', 'meanExp']\n",
    "ref_agg = ref_agg[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode the string features :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode strings\n",
    "encode_string_variable(ref_agg, 'leagueCountry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the labels of the data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ref_nolabels = ref_agg.drop(['rater1', 'rater2'], axis=1)\n",
    "ref_nolabels.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref_std = np.array(preprocessing.scale(ref_nolabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create better labels by taking the mean of the two raters and then apply a binarisation function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ref_agg['meanRaters'] = (ref_agg['rater1'] + ref_agg['rater2'])/2\n",
    "ref_agg['meanRaters'] = ref_agg['meanRaters'].apply(binary_labels)\n",
    "labels = ref_agg['meanRaters']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of a helper function for label inversion and vectorize it for use on numpy arrays :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def invert_labels(x):\n",
    "    if(x==1):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "v = np.vectorize(invert_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline clustering\n",
    "A first try at clustering using all the features of the referee information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#first clustering with all columns\n",
    "kmeans = KMeans(n_clusters=2).fit(ref_std)\n",
    "#predictions:\n",
    "pred = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compute the silhouette score of the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#silhouette score for the predictions\n",
    "metrics.silhouette_score(ref_std, pred, metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Silhouette score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html) is not very high, the cluster are not very consistent, but that's an expected result when we use that amount of features that are very dissimilar. Let's now look at the performance of the clustering regarding Black/White classification. For that purpose, we will use the [f-beta score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html) function with a preference for recall, one population being way bigger than the other, we don't want to only look at accuracy because, for example labelling all players on the first cluster would yield a very good accuracy since there is a 85%/15% ration between Black and White player labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fbeta_score(labels, pred, beta=1.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fbeta_score(labels, v(pred), beta=1.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here we have a really low f-scores both for pred and inverted predictions. We use inverted prediction because we don't know which of the clusters can reprensent well White or Black players, and we see that in this case the inverted pred performs a lot better than the pred, note that silhouette score doesn't change whether we compute it with pred or inverted pred which is intuitive since it doesn't change the clusters themselves but their \"labels\". Let's now try to improve the clusterisation by trying different features combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing itertool to create combinatorics\n",
    "import itertools as iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an array of column indexes for the feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = [i for i in range(0,ref_std.shape[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise storage variables for the future iterative process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "silhouettes = []\n",
    "silhouettes_inv = []\n",
    "f_scores = []\n",
    "f_scores_inv = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying features combinations:\n",
    "\n",
    "In the next cell we try every possible combination of 2-8 features for the clutering. We allow ourselves to perform this heavy computation because our dataset is of reasonable size. At each iteration, we perform the clustering and then store the silhouette score, the f-beta score, the inverted f-beta score (with inverted predictions) and the feature combination used to obtain the clustering. While waiting for the computation, you can enjoy the nice looking and informative progress bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in tqdm_notebook(range(1, ref_std.shape[1]-1), desc='Global'):\n",
    "    #generate combination of features \n",
    "    combinations = list(iter.combinations(columns, len(columns)-i))\n",
    "    #Iterate over every combination\n",
    "    for comb in tqdm_notebook(combinations, desc='Combining', leave=False) :\n",
    "        #Clustering\n",
    "        kmeans = KMeans(n_clusters=2, random_state=1).fit(ref_std[:, comb])\n",
    "        #Extract labels\n",
    "        pred = kmeans.labels_\n",
    "        #Silhouette and f-beta score for predictions\n",
    "        silhouettes.append(metrics.silhouette_score(ref_std[:, comb], pred, metric='euclidean'))\n",
    "        f_scores.append(fbeta_score(labels, pred, beta=1.9)) \n",
    "        #Silhouette and f-beta score for inverted predictions\n",
    "        inv_pred = v(pred)\n",
    "        silhouettes_inv.append(metrics.silhouette_score(ref_std[:, comb], inv_pred, metric='euclidean'))\n",
    "        f_scores_inv.append(fbeta_score(labels, inv_pred, beta=1.9))\n",
    "        #Store feature combination\n",
    "        features.append(comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part we will analize the data obtained previously. Let's take a look at the scatterplots of f-scores and silhouettes in order to get a wide angle on how the clusterings are performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "triples = zip(silhouettes,f_scores, features)\n",
    "points = np.array(zip(silhouettes, f_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "plt.plot(points[:,0], points[:,1], '.')\n",
    "fig1.suptitle('Clustering scores')\n",
    "plt.xlabel('silhouette_score')\n",
    "plt.ylabel('f-beta_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are really poor in terms of f-beta scores. Let's also try to look at the inverted predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "points_inv = np.array(zip(silhouettes, f_scores_inv))\n",
    "plt.plot(points_inv[:,0], points_inv[:,1], '.')\n",
    "fig1.suptitle('Clustering scores for inverted predictions')\n",
    "plt.xlabel('silhouette_score')\n",
    "plt.ylabel('f-beta_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a quick glance at the plot we can see that the f-beta score doesn't go above 0.6 in both cases, meaning that there is no combination of referee related features that yield a good White/Black clustering. But we still want to see what are the best feature combinations possible regarding clustering. We also want to get a look at the accuracy/silhouette tradeoff that may ssem to be a thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pylab as P\n",
    "\n",
    "\n",
    "colors = ['green', 'blue']\n",
    "labels = ['f_scores', 'silhouettes']\n",
    "n, bins, patches = P.hist([f_scores, silhouettes], 75,histtype='bar',\n",
    "                            color=colors,\n",
    "                            label=labels)\n",
    "P.legend()\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Number of points')\n",
    "plt.title('F-beta scores vs. Silhouette scores distributions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that indeed there is a clear tradeoff between f-beta scores and silhouette scores, consodering the two peaks of the distributions. We would like now to find the best points in terms of f-beta score and silhouette score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we select only the points above 0.4 both for f-beta score and silhouette score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bestpoints = points[(points[:,0] > 0.4) & (points[:,1] > 0.4)]\n",
    "plt.plot(bestpoints[:,0], bestpoints[:,1], '.')\n",
    "fig1.suptitle('Clustering scores')\n",
    "plt.xlabel('silhouette_score')\n",
    "plt.ylabel('f-beta_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, in order to select the best points, we compute the convex hull, note here that computing the alpha shape or performing a skyline query would yield better result, nevertheless the time needed for the sheer implementation (because no easily found library) and the extensive computational cost makes it more comfortable to use the convex hull even if the quality of the results is slightly deteriorated  :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "hull = ConvexHull(bestpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig2 = plt.figure()\n",
    "fig1.suptitle('Convex Hull')\n",
    "plt.xlabel('silhouette_score')\n",
    "plt.ylabel('f-beta_score')\n",
    "plt.plot(bestpoints[:,0], bestpoints[:,1], '.')\n",
    "for vertex in hull.vertices:\n",
    "    plt.plot(bestpoints[vertex, 0], bestpoints[vertex, 1], 'o')\n",
    "for simplex in hull.simplices:\n",
    "    plt.plot(bestpoints[simplex, 0], bestpoints[simplex, 1], 'k-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the convex hull points we extract the ones with the best values in terms of f-beta score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sel = []\n",
    "#Collect the hull points\n",
    "for vertex in hull.vertices:\n",
    "    sel.append([bestpoints[vertex, 0], bestpoints[vertex, 1]])\n",
    "sel = np.array(sel)\n",
    "#Select the best ones\n",
    "sel = sel[sel[:,1]>0.48]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we join the score metrics with the features used in the corresponding clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#join the three lists\n",
    "coordinates = zip(silhouettes, f_scores, features)\n",
    "#select the best points\n",
    "results = [r for r in coordinates if np.array(r[0], r[1]) in sel]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better visualisation, we will replace the feature indexes by their names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepare features names\n",
    "col_names = np.array(ref_nolabels.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print the names\n",
    "for i in results:\n",
    "    print(col_names[np.array(i[2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The analysis revealed that there is no way to get a good clustering of black/white players using only referee information, nevertheless we can discuss the features that yield the best classifications. In fact leagueCountry appears in almost all the best cases, meaning that the country where the matches are played may influence on the \"racism\". In order to go deeper in that direction we could perform different clustering per country in order to see if that some leagues are more racist than others. For the whole homework the fact that one population predomines the other makes thing trickier and biases the results. For other referee features that appear in the best clustering instances, card are quite predominant as well as meanIAT.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "0cb583877ee1414db90105b7b0192c92": {
     "views": [
      {
       "cell_index": 166
      }
     ]
    },
    "0d7b0eefd6b94c58aa18c2736bdcd9c2": {
     "views": [
      {
       "cell_index": 166
      }
     ]
    },
    "23fce2f0f8e8481c81e48ee19cdde769": {
     "views": [
      {
       "cell_index": 166
      }
     ]
    },
    "2ab53f11e0814f93b24ab8515de234de": {
     "views": [
      {
       "cell_index": 165
      }
     ]
    },
    "3309c8073b2c4ff2885ddd121805311a": {
     "views": [
      {
       "cell_index": 165
      }
     ]
    },
    "44197ce5424a4d1ba5c5981741ea8245": {
     "views": [
      {
       "cell_index": 165
      }
     ]
    },
    "80ac03eb93d44c7f89bdc45cd68f2639": {
     "views": [
      {
       "cell_index": 166
      }
     ]
    },
    "9a0a387726fc45b593753a298b21a066": {
     "views": [
      {
       "cell_index": 165
      }
     ]
    },
    "a19f4de375b647079f19341c69644540": {
     "views": [
      {
       "cell_index": 165
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
